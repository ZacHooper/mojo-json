from lexer import lex

from parser import is_special_token, parse
from types import (
    Value,
    JSON_SYNTAX,
    JSON_QUOTE,
    JsonList,
    JsonDict,
    JSON_LEFTBRACE,
    JSON_LEFTBRACKET,
    JSON_RIGHTBRACKET,
    JSON_COMMA,
)
from stringify import stringify


fn loads(raw_json: String) raises -> Value:
    var tokens = lex(raw_json)
    return parse(tokens)


fn dumps(value: Value) raises -> String:
    return stringify(value)


fn main() raises:
    var raw_json: String = """
    {
        "name": "John",
        "age": 30,
        "wage": 25.4,
        "is_student": false,
        "has_job": true,
        "is_null": null,
        "nickname": "",
        "address": {
            "street": "Main Street",
            "city": "New York",
            "zip": 10001
        },
        "phone_numbers": [
            "123-456-7890",
            "098-765-4321"
        ]
    }
    """
    var parsed_json = loads(raw_json)
    print(dumps(parsed_json))
